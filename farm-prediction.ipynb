{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-02T11:55:17.779885Z",
     "start_time": "2025-03-02T11:55:17.194524Z"
    }
   },
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"atharvaingle/crop-recommendation-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.10)\n",
      "Path to dataset files: /home/galich/.cache/kagglehub/datasets/atharvaingle/crop-recommendation-dataset/versions/1\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T21:07:09.724141Z",
     "start_time": "2025-02-27T21:07:09.714382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(f\"{path}/Crop_recommendation.csv\")\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check column names\n",
    "print(df.columns)\n"
   ],
   "id": "24a670cc83c7912",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    N   P   K  temperature   humidity        ph    rainfall label\n",
      "0  90  42  43    20.879744  82.002744  6.502985  202.935536  rice\n",
      "1  85  58  41    21.770462  80.319644  7.038096  226.655537  rice\n",
      "2  60  55  44    23.004459  82.320763  7.840207  263.964248  rice\n",
      "3  74  35  40    26.491096  80.158363  6.980401  242.864034  rice\n",
      "4  78  42  42    20.130175  81.604873  7.628473  262.717340  rice\n",
      "Index(['N', 'P', 'K', 'temperature', 'humidity', 'ph', 'rainfall', 'label'], dtype='object')\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T21:07:10.882365Z",
     "start_time": "2025-02-27T21:07:10.864120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encode labels as integers\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['label'])  # Converts crop names to integers\n",
    "\n",
    "# Standardize input features\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(df.drop(columns=['label']))\n",
    "\n",
    "# One-hot encode labels for multi-class classification\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y_one_hot = encoder.fit_transform(df[['label']])  # Convert labels to one-hot\n",
    "\n",
    "# Convert to float\n",
    "x = x.astype(float)\n",
    "y_one_hot = y_one_hot.astype(float)\n",
    "\n",
    "print(x.shape, y_one_hot.shape)"
   ],
   "id": "a84300dea72babfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200, 7) (2200, 22)\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-27T21:28:47.040285Z",
     "start_time": "2025-02-27T21:28:47.029943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def outer_product(vec_a, vec_b):\n",
    "    assert len(vec_a) > 0 and len(vec_b) > 0, \"Input vectors must not be empty\"\n",
    "\n",
    "    out = np.zeros((len(vec_a), len(vec_b)))\n",
    "\n",
    "    for i in range(len(vec_a)):  # Iterate over vec_a (rows)\n",
    "        for j in range(len(vec_b)):  # Iterate over vec_b (columns)\n",
    "            out[i][j] = vec_a[i] * vec_b[j]  # Multiply element-wise\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x))  # Stabilize softmax\n",
    "    return exp_x / np.sum(exp_x)  # Convert scores into probabilities\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    return softmax(np.dot(input, weights))  # Matrix multiplication + softmax\n"
   ],
   "id": "305878083048c05c",
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T10:47:52.357834Z",
     "start_time": "2025-03-02T10:47:36.834568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Assuming num_inputs = 7 (features) and num_classes = 22 (crops)\n",
    "num_inputs = 7\n",
    "num_classes = 22\n",
    "\n",
    "weights = np.random.randn(num_inputs, num_classes) * 0.01  # Small random weights\n",
    "alpha = 0.01  # Learning rate\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for i in range(len(x)):  # Loop over dataset\n",
    "        input = x[i]  # Features\n",
    "        true = y_one_hot[i]  # One-hot encoded label\n",
    "\n",
    "        # Forward pass\n",
    "        pred = neural_network(input, weights)\n",
    "\n",
    "        # Compute loss (cross-entropy)\n",
    "        loss = (pred - true) ** 2  # Avoid log(0)\n",
    "        total_loss += loss\n",
    "\n",
    "        # Compute gradient (backpropagation)\n",
    "        delta = pred - true  # Gradient of softmax + cross-entropy\n",
    "        weight_deltas = outer_product(input, delta) # Outer product\n",
    "        # Update weights\n",
    "        weights -= alpha * weight_deltas\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss}\")\n",
    "\n",
    "# Save weights to JSON\n",
    "weights_dict = {\"weights\": weights.tolist()}  # Convert numpy array to list for JSON\n",
    "with open(\"crop-predict-app/weights.json\", \"w\") as f:\n",
    "    json.dump(weights_dict, f)\n",
    "\n",
    "print(\"Final Weights saved to weights.json\")\n"
   ],
   "id": "10faf71ebd79f734",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: [22.16867461 68.46823189 81.50197219 38.70491256 58.68368714 68.16430546\n",
      " 66.8745343  31.64610583 80.94951724 48.06247786 78.91870226 85.68411172\n",
      " 63.96821262 80.06570799 77.15162642 55.62734828 68.98767887 68.11525695\n",
      " 72.62634169 76.83348494 51.06164239 71.46468094]\n",
      "Epoch 2, Loss: [17.80332445 36.19441638 64.37510738 16.22172459 29.35531063 37.50567351\n",
      " 41.82415759 23.59576058 66.2721067  28.81560758 55.52097719 71.2493308\n",
      " 36.18813395 67.1967669  56.05522432 32.09616025 47.36668691 45.28282876\n",
      " 46.13513856 56.16363921 36.71581608 55.38200792]\n",
      "Epoch 3, Loss: [16.38340214 20.47084103 54.91287469  9.88506897 21.44247853 24.62114095\n",
      " 32.88579264 20.50238707 59.70681242 24.53490852 43.82180746 58.81901645\n",
      " 27.79106912 61.15821834 42.76296531 26.86578203 41.63749482 38.09633411\n",
      " 35.20766689 45.82112416 34.10426347 46.71854205]\n",
      "Epoch 4, Loss: [15.15487726 13.43044546 48.5055631   6.73859356 17.64961167 18.12571866\n",
      " 27.69797852 18.51899084 55.98429773 21.50261151 37.14930435 49.18818705\n",
      " 22.22474905 55.30314438 33.79449792 24.33950443 38.44986751 34.42733186\n",
      " 29.18916158 39.08698321 32.00392498 40.5756008 ]\n",
      "Epoch 5, Loss: [13.96265802  9.84578614 43.77134626  5.03675808 15.32319244 14.45672789\n",
      " 24.23117446 16.78159438 53.36296131 19.24710085 32.98678888 42.50623848\n",
      " 18.29283658 50.23124311 27.85402455 22.59670863 35.97853038 31.92826946\n",
      " 25.40110984 34.51415053 30.79871474 36.0624413 ]\n",
      "Epoch 6, Loss: [12.8016147   7.7359879  40.12456351  3.98732738 13.73508241 12.15295049\n",
      " 21.75186254 15.21100042 51.32445953 17.48920467 30.18777396 37.85918661\n",
      " 15.43696147 45.95854951 23.79981294 21.20890928 33.84916824 29.99761923\n",
      " 22.77888014 31.13166876 30.07446318 32.59068714]\n",
      "Epoch 7, Loss: [11.68900777  6.35744432 37.24644061  3.27225851 12.57359523 10.58584915\n",
      " 19.88247813 13.78158068 49.65756025 16.07537976 28.17584765 34.46757737\n",
      " 13.30137272 42.34752213 20.89857069 20.03671107 31.92732293 28.39907088\n",
      " 20.848523   28.44656829 29.59750844 29.82599869]\n",
      "Epoch 8, Loss: [10.63964594  5.38801974 34.92969059  2.75203475 11.68034673  9.45438104\n",
      " 18.41267575 12.47923587 48.25219425 14.91253969 26.65123346 31.86028733\n",
      " 11.66083104 39.27251122 18.72463815 19.02095385 30.15644693 27.01843437\n",
      " 19.36249845 26.21337089 29.25571092 27.56808276]\n",
      "Epoch 9, Loss: [ 9.66269149  4.66897559 33.03090528  2.35642163 10.9662739   8.59934106\n",
      " 17.21846211 11.29464639 47.04319065 13.93975614 25.44818963 29.76787488\n",
      " 10.36995148 36.63457553 17.03012899 18.12940351 28.51097462 25.79388481\n",
      " 18.17824489 24.30017393 28.99332412 25.68797023]\n",
      "Epoch 10, Loss: [ 8.76254126  4.11390815 31.44876576  2.04590307 10.37761614  7.92963811\n",
      " 16.22281216 10.22039082 45.98852411 13.11489145 24.46884163 28.03223758\n",
      "  9.33258955 34.35581826 15.66552783 17.34065585 26.97800293 24.68905838\n",
      " 17.20827362 22.62946827 28.78116005 24.09795923]\n",
      "Epoch 11, Loss: [ 7.94009711  3.67202733 30.11069634  1.79632167  9.88015217  7.38979166\n",
      " 15.37556605  9.2495652  45.05920927 12.40761232 23.65184489 26.55604332\n",
      "  8.4835232  32.37408422 14.53685367 16.6386773  25.549648   23.6810078\n",
      " 16.3961954  21.15174289 28.60315973 22.73591993]\n",
      "Epoch 12, Loss: [ 7.1937891   3.31160524 28.96395675  1.59196075  9.45116785  6.94426014\n",
      " 14.64267678  8.37521378 44.23412787 11.79539724 22.95675651 25.27626043\n",
      "  7.77738754 30.63932978 13.58265951 16.01069641 24.21983607 22.7543041\n",
      " 15.70411637 19.8329817  28.45005201 21.55640795]\n",
      "Epoch 13, Loss: [ 6.52033846  3.01182246 27.96961366  1.42209594  9.07505885  6.56930963\n",
      " 14.0001874   7.59017887 43.497202   11.26110418 22.3557704  24.15012361\n",
      "  7.18187839 29.11104976 12.7613205  15.44624028 22.98301238 21.8979553\n",
      " 15.10562278 18.64835219 28.31621119 20.5253175 ]\n",
      "Epoch 14, Loss: [ 5.9153339   2.75845227 27.09845333  1.27913126  8.74078526  6.24853143\n",
      " 13.43070827  6.88715147 42.83576414 10.79141841 21.82909322 23.14741294\n",
      "  6.67348929 27.75633566 12.04374216 14.93659988 21.83368626 21.10371205\n",
      " 14.58170347 17.57882565 28.19803537 19.61650716]\n",
      "Epoch 15, Loss: [ 5.37367826  2.54143771 26.32819859  1.15752368  8.44033163  5.9702425\n",
      " 12.92127306  6.25880607 42.2395697  10.37582424 21.36222249 22.24601826\n",
      "  6.23477601 26.5483552  11.40901898 14.47447839 20.76633077 20.36509487\n",
      " 14.11828894 16.60926497 28.09308129 18.80958507]\n",
      "Epoch 16, Loss: [ 4.88993794  2.3534622  25.64159819  1.05312884  8.16774122  5.72591172\n",
      " 12.46198589  5.6979568  41.70016956 10.00590098 20.94427135 21.42927916\n",
      "  5.85256076 25.46514427 10.84175786 14.05373184 19.7754199  19.67681436\n",
      " 13.70471395 15.72728489 27.99959001 18.08840583]\n",
      "Epoch 17, Loss: [ 4.45861232  2.18907043 25.02509969  0.96278512  7.91849219  5.50917126\n",
      " 12.04513932  5.19770106 41.2104924   9.67482692 20.56689693 20.68432457\n",
      "  5.51672726 24.48864436 10.33037475 13.66916619 18.85550709 19.03441399\n",
      " 13.33272588 14.92253784 27.91622059 17.4400213 ]\n",
      "Epoch 18, Loss: [ 4.0743337   2.04410754 24.46791513  0.8840393   7.68908433  5.31517562\n",
      " 11.66462251  4.75153392 40.76455421  9.37702078 20.2235916  20.00099774\n",
      "  5.21939546 23.60393646  9.8659794  13.31637386 18.00130432 18.43404364\n",
      " 12.9958256  14.18624445 27.8418974  16.8539304 ]\n",
      "Epoch 19, Loss: [ 3.73200704  1.91535018 23.96135339  0.81495994  7.47675912  5.14017413\n",
      " 11.31551353  4.35342717 40.35724809  9.10787685 19.90920051 19.37113737\n",
      "  4.95434559 22.79863217  9.44162625 12.99160046 17.20774645 17.87231215\n",
      " 12.6888172  13.51087069 27.77572091 16.32153154]\n",
      "Epoch 20, Loss: [ 3.42689889  1.80025687 23.49833602  0.75400712  7.27930642  4.981219\n",
      " 10.99379227  3.99787401 39.98418648  8.8635656  19.61958482 18.78808252\n",
      "  4.71660895 22.06239009  9.05179988 12.69163566 16.47003695 17.34618901\n",
      " 12.40749241 12.88989615 27.71691449 15.83571601]\n",
      "Epoch 21, Loss: [ 3.15468552  1.69679498 23.07304089  0.69993936  7.09492849  4.83596136\n",
      " 10.69613396  3.67990392 39.64157947  8.64088127 19.3513814  18.24632299\n",
      "  4.50217262 21.38653146  8.69205434 12.41372359 15.78367622 16.85293738\n",
      " 12.14840437 12.31764144 27.66479206 15.39056116]\n",
      "Epoch 22, Loss: [ 2.91146976  1.60331818 22.6806362   0.65174587  6.92214279  4.70250616\n",
      " 10.4197582   3.39507437 39.32613851  8.43712374 19.10182813 17.74124649\n",
      "  4.30776297 20.76373403  8.35875588 12.15548909 15.14447524 16.39006709\n",
      " 11.90870201 11.7891351  27.61873794 14.98109599]\n",
      "Epoch 23, Loss: [ 2.69377548  1.51847795 22.31707928  0.60859635  6.75971133  4.57930704\n",
      " 10.16231663  3.13944571 39.03499892  8.25000584 18.8686345  17.26895228\n",
      "  4.13068495 20.18778763  8.0488964  11.91487709 14.54855793 15.95530084\n",
      " 11.68600652 11.30000824 27.57819396 14.60311985]\n",
      "Epoch 24, Loss: [ 2.49852704  1.44115853 21.97896254  0.56980332  6.60658859  4.46508904\n",
      "  9.92180812  2.9095455  38.76565644  8.07758009 18.64988451 16.82611112\n",
      "  3.96870107 19.65339834  7.75995629 11.69010246 13.99235499 15.54654902\n",
      " 11.47831775 10.84640908 27.54265087 14.25306065]\n",
      "Epoch 25, Loss: [ 2.32301969  1.37042831 21.66339409  0.53479335  6.46188262  4.35879087\n",
      "  9.69651399  2.7023269  38.51591491  7.91818007 18.44396264 16.4098584\n",
      "  3.81993927 19.15603083  7.48980223 11.47960865 13.47259204 15.16189012\n",
      " 11.2839422  10.42493237 27.51164242 13.92786304]\n",
      "Epoch 26, Loss: [ 2.16488534  1.30550313 21.36790431  0.50308493  6.32482549  4.25952133\n",
      "  9.48494766  2.51512504 38.28384261  7.7703733  18.24949675 16.01771136\n",
      "  3.68282205 18.69178099  7.23661004 11.28203332 12.98627391 14.79955507\n",
      " 11.10143687 10.03256031 27.48474094 13.62489941]\n",
      "Epoch 27, Loss: [ 2.02205694  1.24571796 21.09037199  0.47427129  6.19475059  4.16652595\n",
      "  9.28581522  2.34561386 38.06773561  7.63292301 18.06531361 15.64750414\n",
      "  3.55601128 18.25727258  6.9988058  11.09617978 12.53066672 14.45791396\n",
      " 10.92956509  9.66661255 27.46155397 13.3418984 ]\n",
      "Epoch 28, Loss: [ 1.89273362  1.19050504 20.82896539  0.44800677  6.07107503  4.07916118\n",
      "  9.09798409  2.19176513 37.86608685  7.50475701 17.89040381 15.2973362\n",
      "  3.4383649  17.84957284  6.77502046 10.92099322 12.10327892 14.13546472\n",
      " 10.76726129  9.3247035  27.44172146 13.07688723]\n",
      "Epoch 29, Loss: [ 1.77534786  1.1393766  20.58209487  0.42399609  5.95328575  3.99687425\n",
      "  8.92045789  2.05181079 37.67755999  7.38494208 17.72389384 14.96553091\n",
      "  3.32890263 17.4661234   6.56405442 10.75554068 11.70184216 13.83082288\n",
      " 10.61360273  9.00470572 27.42491329 12.82814465]\n",
      "Epoch 30, Loss: [ 1.66853546  1.09191126 20.34837444  0.40198577  5.84092847  3.91918729\n",
      "  8.75235601  1.92420887 37.50096706  7.27266294 17.56502376 14.65060195\n",
      "  3.22677855 17.10468338  6.36484952 10.5989944  11.32429259 13.54271246\n",
      " 10.46778658  8.70471831 27.41082714 12.59416251]\n",
      "Epoch 31, Loss: [ 1.57110858  1.04774307 20.12659045  0.38175722  5.7335988   3.84568467\n",
      "  8.59289699  1.8076133  37.33524949  7.16720478 17.41312905 14.35122591\n",
      "  3.13125906 16.76328229  6.17646693 10.45061759 10.96875286 13.26995745\n",
      " 10.32911126  8.42303962 27.39918644 12.37361405]\n",
      "Epoch 32, Loss: [ 1.48203192  1.00655269 19.91567579  0.36312104  5.63093501  3.77600285\n",
      "  8.44138465  1.70084738 37.17946179  7.06793869 17.26762591 14.0662196\n",
      "  3.04170498 16.44018097  5.99806917 10.30975255 10.63351528 13.01147414\n",
      " 10.19696106  8.15814346 27.38973849 12.16532761]\n",
      "Epoch 33, Loss: [ 1.40040192  0.9680602  19.71468862  0.34591252  5.53261215  3.70982219\n",
      "  8.29719665  1.6028807  37.03275758  6.97430953 17.12799916 13.79452121\n",
      "  2.95755698 16.1338389   5.82890569 10.17581047 10.31702605 12.76626378\n",
      " 10.0707935   7.90865859 27.3822527  11.9682648 ]\n",
      "Epoch 34, Loss: [ 1.32542863  0.93201919 19.52279463  0.32998784  5.4383371   3.64686029\n",
      "  8.15977484  1.51280919 36.89437755  6.88582571 16.99379225 13.53517459\n",
      "  2.87832358 15.84288685  5.66830094 10.0482628  10.01787072 12.53340596\n",
      "  9.95012878  7.67335064 27.37651886 11.78150213]\n",
      "Epoch 35, Loss: [ 1.25642017  0.89821195 19.33925227  0.31522093  5.34784451  3.58686646\n",
      "  8.02861717  1.42983792 36.76363903  6.80205057 16.86459897 13.28731592\n",
      "  2.80357121 15.56610389  5.51564455  9.9266338   9.73476094 12.31205234\n",
      "  9.83454095  7.45110653 27.37234562 11.60421568]\n",
      "Epoch 36, Loss: [ 1.19276923  0.86644541 19.16340027  0.30150093  5.26089337  3.52961727\n",
      "  7.90327075  1.35326637 36.63992707  6.72259513 16.74005656 13.05016253\n",
      "  2.73291602 15.30239785  5.3703832   9.81049423  9.46652233 12.10142092\n",
      "  9.72365061  7.24092071 27.36955893 11.43566804]\n",
      "Epoch 37, Loss: [ 1.13394164  0.83654773 18.99464716  0.28873004  5.17726408  3.47491273\n",
      "  7.78332594  1.2824758  36.52268656  6.6471119  16.61983989 12.82300323\n",
      "  2.66601699 15.05078888  5.23201368  9.69945582  9.21208348 11.90079063\n",
      "  9.61711859  7.04188317 27.36800065 11.2751973 ]\n",
      "Epoch 38, Loss: [ 1.07946647  0.80836553 18.83246236  0.27682166  5.096756    3.42257319\n",
      "  7.66841134  1.21691836 36.4114155   6.57528955 16.50365655 12.60519012\n",
      "  2.60257014 14.81039533  5.10007712  9.59316657  8.97046599 11.70949644\n",
      "  9.51464076  6.85316897 27.36752725 11.12220762]\n",
      "Epoch 39, Loss: [ 1.0289276   0.78176146 18.67636859  0.26569892  5.01918532  3.37243668\n",
      "  7.55818939  1.15610789 36.30565906  6.5068485  16.39124273 12.39613155\n",
      "  2.54230366 14.58042175  4.97415398  9.49130663  8.74077553 11.52692479\n",
      "  9.41594354  6.67402897 27.36800855 10.97616122]\n",
      "Epoch 40, Loss: [ 0.98195651  0.75661218 18.52593536  0.25529339  4.94438323  3.32435673\n",
      "  7.4523526   1.09961194 36.20500441  6.44153698 16.28235966 12.19528594\n",
      "  2.4849738  14.36014856  4.85385985  9.39358474  8.52219375 11.35250935\n",
      "  9.32078006  6.50378173 27.3693266  10.83657146]\n",
      "Epoch 41, Loss: [ 0.93822606  0.73280663 18.38077346  0.24554396  4.87219433  3.27820042\n",
      "  7.35062026  1.04704495 36.10907624  6.37912773 16.17679062 12.0021565\n",
      "  2.43036134 14.14892318  4.73884172  9.29973511  8.313971   11.18572717\n",
      "  9.22892691  6.34180635 27.3713746  10.7029969 ]\n",
      "Epoch 42, Loss: [ 0.89744519  0.71024456 18.24053008  0.23639594  4.80247528  3.23384682\n",
      "  7.25273561  0.99806243 36.01753272  6.31941513 16.07433833 11.81628659\n",
      "  2.37826859 13.94615236  4.62877479  9.20951468  8.1154198  11.02609511\n",
      "  9.14018134  6.18753621 27.37405594 10.57503614]\n",
      "Epoch 43, Loss: [ 0.85935439  0.68883524 18.10488474  0.22780025  4.73509357  3.19118556\n",
      "  7.15846332  0.95235587 35.93006208  6.26221271 15.97482274 11.63725565\n",
      "  2.32851681 13.75129553  4.52335971  9.12270078  7.92590896 10.87316661\n",
      "  9.05435885  6.04045335 27.37728328 10.4523234 ]\n",
      "Epoch 44, Loss: [ 0.82372172  0.6684964  17.97354564  0.21971276  4.66992648  3.15011569\n",
      "  7.06758727  0.90964843 35.84637948  6.207351   15.8780791  11.46467564\n",
      "  2.28094404 13.56385901  4.42232008  9.03908902  7.74485829 10.7265286\n",
      "  8.97129109  5.9000836  27.3809777  10.33452459]\n",
      "Epoch 45, Loss: [ 0.79033946  0.64915323 17.84624653  0.21209366  4.60686015  3.11054462\n",
      "  6.97990868  0.86969116 35.76622433  6.15467565 15.78395628 11.29818791\n",
      "  2.2354031  13.38339101  4.32540034  8.95849141  7.5717339  10.58579884\n",
      "  8.89082406  5.76599219 27.38506802 10.221334  ]\n",
      "Epoch 46, Loss: [ 0.7590212   0.63073761 17.72274402  0.20490702  4.54578875  3.07238726\n",
      "  6.89524434  0.83225979 35.68935784  6.10404579 15.69231533 11.13746043\n",
      "  2.19176002 13.2094772   4.23236382  8.8807348   7.40604388 10.45062334\n",
      "  8.81281652  5.63777987 27.38948999 10.11247125]\n",
      "Epoch 47, Loss: [ 0.72959928  0.61318734 17.60281512  0.19812028  4.48661378  3.03556519\n",
      "  6.81342513  0.79715186 35.61556093  6.0553326  15.6030282  10.98218529\n",
      "  2.14989254 13.04173687  4.14299106  8.80565938  7.24733451 10.32067408\n",
      "  8.73713865  5.51507951 27.39418573 10.00767876]\n",
      "Epoch 48, Loss: [ 0.70192262  0.59644556 17.48625519  0.19170391  4.42924337  3.00000606\n",
      "  6.73429472  0.76418428 35.54463235  6.00841806 15.51597665 10.83207657\n",
      "  2.10968887 12.8798195   4.0570783   8.73311742  7.09518678 10.19564689\n",
      "  8.66367083  5.397553   27.39910314  9.90671944]\n",
      "Epoch 49, Loss: [ 0.6758548   0.58046016 17.3728761   0.18563109  4.37359178  2.9656429\n",
      "  6.65770832  0.73319118 35.4763869   5.96319382 15.43105125 10.68686832\n",
      "  2.0710466  12.72340185  3.97443611  8.66297216  6.94921331 10.07525949\n",
      "  8.59230259  5.28488854 27.40419533  9.80937467]\n",
      "Epoch 50, Loss: [ 0.65127243  0.56518334 17.26250454  0.17987736  4.31957881  2.93241369\n",
      "  6.58353166  0.70402205 35.41065406  5.91956025 15.34815056 10.54631288\n",
      "  2.03387172 12.57218522  3.89488817  8.59509678  6.80905555  9.95924975\n",
      "  8.5229317   5.17679822 27.40942018  9.71544253]\n",
      "Epoch 51, Loss: [ 0.62806368  0.55057114 17.15498063  0.17442044  4.26712938  2.90026084\n",
      "  6.51164004  0.6765401  35.34727651  5.8774256  15.26718032 10.4101793\n",
      "  1.99807778 12.4258932   3.81827019  8.52937351  6.67438125  9.84737406\n",
      "  8.45546338  5.0730158  27.41473986  9.62473621]\n",
      "Epoch 52, Loss: [ 0.60612702  0.53658307 17.05015662  0.16923996  4.2161731   2.86913079\n",
      "  6.4419175   0.65062077 35.28610905  5.83670519 15.18805282 10.27825191\n",
      "  1.96358514 12.28426955  3.74442895  8.46569281  6.5448822   9.73940583\n",
      "  8.38980951  4.97329479 27.42012048  9.53708259]\n",
      "Epoch 53, Loss: [ 0.58537009  0.52318183 16.94789577  0.16431727  4.16664391  2.83897367\n",
      "  6.37425602  0.62615053 35.22701742  5.79732077 15.11068631 10.1503291\n",
      "  1.93032031 12.14707634  3.67322136  8.40395267  6.42027215  9.63513418\n",
      "  8.3258881   4.87740668 27.42553168  9.45232104]\n",
      "Epoch 54, Loss: [ 0.56570879  0.51033294 16.8480713   0.15963529  4.11847972  2.80974294\n",
      "  6.30855491  0.6030257  35.16987741  5.75919989 15.03500445 10.02622216\n",
      "  1.89821537 12.01409236  3.60451368  8.34405797  6.30028499  9.53436263\n",
      "  8.26362264  4.78513941 27.4309463   9.37030226]\n",
      "Epoch 55, Loss: [ 0.54706634  0.4980045  16.75056553  0.15517833  4.07162213  2.78139514\n",
      "  6.24472011  0.5811515  35.11457394  5.72227542 14.96093583  9.90575426\n",
      "  1.86720742 11.88511159  3.53818079  8.28591988  6.18467304  9.43690802\n",
      "  8.20294164  4.69629589 27.43634012  9.29088729]\n",
      "Epoch 56, Loss: [ 0.5293726   0.48616701 16.65526904  0.15093195  4.02601612  2.75388959\n",
      "  6.18266375  0.56044112 35.06100028  5.68648503 14.88841359  9.78875951\n",
      "  1.83723818 11.75994192  3.47410553  8.22945533  6.07320556  9.34259945\n",
      "  8.14377821  4.61069278 27.44169155  9.21394663]\n",
      "Epoch 57, Loss: [ 0.51256334  0.47479306 16.56207997  0.14688288  3.98160985  2.72718822\n",
      "  6.12230354  0.54081502 35.00905739  5.65177074 14.81737499  9.67508214\n",
      "  1.80825349 11.63840395  3.41217807  8.17458658  5.96566735  9.25127734\n",
      "  8.0860696   4.52815931 27.4469814   9.13935944]\n",
      "Epoch 58, Loss: [ 0.49657971  0.46385723 16.47090335  0.14301887  3.93835436  2.70125527\n",
      "  6.06356242  0.52220013 34.95865322  5.61807863 14.74776111  9.56457571\n",
      "  1.78020303 11.52032993  3.35229539  8.12124078  5.86185749  9.16279255\n",
      "  8.02975692  4.44853625 27.45219265  9.0670128 ]\n",
      "Epoch 59, Loss: [ 0.48136765  0.45333587 16.38165054  0.1393286   3.89620343  2.6760572\n",
      "  6.00636807  0.50452935 34.90970217  5.58535838 14.67951655  9.45710244\n",
      "  1.75303992 11.40556282  3.29436076  8.06934956  5.76158824  9.07700555\n",
      "  7.97478476  4.371675   27.45731023  8.99680108]\n",
      "Epoch 60, Loss: [ 0.46687749  0.44320697 16.29423868  0.13580163  3.85511335  2.65156245\n",
      "  5.9506526   0.48774087 34.86212454  5.55356306 14.6125891   9.35253256\n",
      "  1.72672048 11.29395542  3.2382833   8.0188487   5.66468398  8.99378577\n",
      "  7.92110094  4.29743668 27.46232087  8.92862534]\n",
      "Epoch 61, Loss: [ 0.45306349  0.43345002 16.20859021  0.13242828  3.81504276  2.62774132\n",
      "  5.8963522   0.47177781 34.81584609  5.5226488  14.54692957  9.25074371\n",
      "  1.7012039  11.18536957  3.18397752  7.96967784  5.57098026  8.91301084\n",
      "  7.86865626  4.22569141 27.46721291  8.86239282]\n",
      "Epoch 62, Loss: [ 0.4398835   0.42404589 16.12463248  0.12919959  3.77595248  2.60456582\n",
      "  5.84340681  0.45658766 34.77079757  5.49257454 14.48249149  9.15162047\n",
      "  1.67645205 11.07967546  3.13136297  7.92178013  5.48032299  8.83456605\n",
      "  7.81740424  4.15631758 27.47197615  8.79801641]\n",
      "Epoch 63, Loss: [ 0.4272986   0.41497669 16.04229733  0.12610723  3.73780536  2.58200956\n",
      "  5.79175988  0.44212196 34.72691435  5.46330185 14.41923098  9.05505381\n",
      "  1.65242927 10.97675101  3.08036387  7.87510205  5.39256761  8.75834372\n",
      "  7.76730092  4.08920121 27.4766017   8.7354143 ]\n",
      "Epoch 64, Loss: [ 0.41527284  0.40622571 15.96152073  0.12314349  3.7005662   2.5600476\n",
      "  5.74135809  0.42833591 34.68413606  5.43479466 14.35710649  8.96094069\n",
      "  1.62910212 10.87648126  3.03090879  7.8295931   5.3075784   8.68424276\n",
      "  7.71830472  4.02423541 27.48108189  8.6745095 ]\n",
      "Epoch 65, Loss: [ 0.40377294  0.39777731 15.8822425   0.12030118  3.66420152  2.53865637\n",
      "  5.69215113  0.41518804 34.64240627  5.40701911 14.29607869  8.86918365\n",
      "  1.60643926 10.77875784  2.98293034  7.78520562  5.22522783  8.61216811\n",
      "  7.67037617  3.9613198  27.48541011  8.61522952]\n",
      "Epoch 66, Loss: [ 0.3927681   0.38961683 15.80440596  0.11757362  3.62867955  2.51781358\n",
      "  5.64409147  0.40263997 34.60167218  5.37994339 14.23611029  8.77969041\n",
      "  1.58441123 10.68347851  2.93636491  7.74189457  5.14539596  8.54203036\n",
      "  7.62347786  3.90036006 27.48958075  8.55750605]\n",
      "Epoch 67, Loss: [ 0.38222972  0.38173052 15.72795774  0.11495457  3.59397006  2.49749813\n",
      "  5.59713421  0.39065608 34.56188434  5.35353757 14.17716591  8.69237353\n",
      "  1.56299039 10.59054671  2.89115241  7.6996174   5.06796989  8.47374535\n",
      "  7.57757424  3.84126745 27.49358907  8.50127462]\n",
      "Epoch 68, Loss: [ 0.37213127  0.37410548 15.65284747  0.11243822  3.56004431  2.47769\n",
      "  5.55123684  0.37920333 34.52299644  5.32777345 14.11921192  8.60715014\n",
      "  1.54215069 10.49987116  2.84723603  7.65833379  4.99284327  8.40723377\n",
      "  7.5326315   3.78395847 27.49743114  8.44647438]\n",
      "Epoch 69, Loss: [ 0.36244809  0.36672959 15.5790276   0.11001916  3.52687492  2.45837022\n",
      "  5.50635913  0.36825102 34.48496503  5.30262447 14.0622164   8.52394159\n",
      "  1.52186762 10.41136548  2.80456205  7.61800559  4.91991581  8.34242083\n",
      "  7.48861747  3.72835442 27.50110376  8.39304782]\n",
      "Epoch 70, Loss: [ 0.35315723  0.35959146 15.50645318  0.1076923   3.4944358   2.43952076\n",
      "  5.46246295  0.35777061 34.44774935  5.27806557 14.00614892  8.44267319\n",
      "  1.50211807 10.32494788  2.76307959  7.57859662  4.84909292  8.27923596\n",
      "  7.44550148  3.67438111 27.50460437  8.34094051]\n",
      "Epoch 71, Loss: [ 0.34423733  0.35268034 15.43508169  0.10545292  3.46270207  2.42112451\n",
      "  5.41951215  0.34773552 34.41131114  5.25407305 13.95098055  8.363274\n",
      "  1.48288022 10.24054081  2.72274047  7.54007256  4.78028526  8.21761253\n",
      "  7.40325431  3.62196854 27.507931    8.29010097]\n",
      "Epoch 72, Loss: [ 0.33566844  0.34598613 15.36487285  0.10329658  3.43165001  2.4031652\n",
      "  5.3774724   0.33812101 34.37561442  5.23062455 13.8966837   8.28567655\n",
      "  1.46413349 10.15807072  2.68349902  7.50240084  4.71340841  8.15748755\n",
      "  7.36184805  3.57105057 27.51108223  8.24048039]\n",
      "Epoch 73, Loss: [ 0.32743199  0.33949931 15.2957885   0.1012191   3.40125698  2.38562734\n",
      "  5.33631112  0.328904   34.3406254   5.20769889 13.84323205  8.20981666\n",
      "  1.4458584  10.07746779  2.64531193  7.4655505   4.64838254  8.09880144\n",
      "  7.32125607  3.52156473 27.5140571   8.19203252]\n",
      "Epoch 74, Loss: [ 0.3195106   0.33321088 15.22779242  0.09921661  3.37150132  2.36849618\n",
      "  5.29599734  0.32006295 34.30631225  5.18527604 13.79060048  8.13563323\n",
      "  1.42803653  9.99866565  2.6081381   7.42949213  4.5851321   8.04149784\n",
      "  7.28145287  3.47345193 27.51685509  8.14471344]\n",
      "Epoch 75, Loss: [ 0.31188804  0.32711236 15.16085022  0.09728542  3.34236238  2.35175768\n",
      "  5.25650158  0.31157776 34.27264503  5.16333699 13.73876502  8.06306804\n",
      "  1.41065045  9.92160123  2.5719385   7.39419773  4.52358557  7.98552334\n",
      "  7.24241411  3.42665621 27.51947607  8.09848147]\n",
      "Epoch 76, Loss: [ 0.3045491   0.32119572 15.09492922  0.09542212  3.31382038  2.33539843\n",
      "  5.21779581  0.30342961 34.23959552  5.14186375 13.68770274  7.99206562\n",
      "  1.39368362  9.84621447  2.53667605  7.35964066  4.46367515  7.93082732\n",
      "  7.20411645  3.38112462 27.52192024  8.05329701]\n",
      "Epoch 77, Loss: [ 0.29747955  0.31545338 15.02999834  0.09362346  3.2858564   2.31940566\n",
      "  5.17985333  0.29560093 34.20713713  5.12083921 13.6373917   7.92257304\n",
      "  1.37712039  9.7724482   2.50231548  7.32579555  4.40533656  7.87736178\n",
      "  7.16653755  3.33680695 27.52418814  8.00912239]\n",
      "Epoch 78, Loss: [ 0.29066605  0.30987816 14.96602797  0.09188641  3.25845234  2.30376716\n",
      "  5.14264869  0.28807524 34.17524478  5.10024714 13.58781091  7.85453981\n",
      "  1.36094586  9.70024795  2.46882327  7.29263819  4.3485088   7.82508116\n",
      "  7.12965599  3.29365557 27.52628056  7.96592176]\n",
      "Epoch 79, Loss: [ 0.28409609  0.30446326 14.90298992  0.0902081   3.23159084  2.28847128\n",
      "  5.10615761  0.28083711 34.14389481  5.08007212 13.53894029  7.78791771\n",
      "  1.34514592  9.62956175  2.4361675   7.26014553  4.29313396  7.77394218\n",
      "  7.09345122  3.25162532 27.52819858  7.923661  ]\n",
      "Epoch 80, Loss: [ 0.2777579   0.29920225 14.8408573   0.08858584  3.20525529  2.27350688\n",
      "  5.07035695  0.27387208 34.11306485  5.06029946 13.49076055  7.72266067\n",
      "  1.32970714  9.56034004  2.40431777  7.22829554  4.23915703  7.7239037\n",
      "  7.05790354  3.21067327 27.52994346  7.8823076 ]\n",
      "Epoch 81, Loss: [ 0.27164043  0.29408901 14.77960445  0.08701709  3.17942976  2.25886329\n",
      "  5.0352246   0.26716658 34.0827338   5.04091522 13.44325325  7.65872466\n",
      "  1.31461674  9.49253546  2.37324512  7.1970672   4.18652569  7.67492663\n",
      "  7.02299401  3.17075866 27.53151668  7.84183057]\n",
      "Epoch 82, Loss: [ 0.26573331  0.28911774 14.71920687  0.08549944  3.15409897  2.24453033\n",
      "  5.00073943  0.26070785 34.05288171  5.02190607 13.39640065  7.59606757\n",
      "  1.29986258  9.4261028   2.34292194  7.16644043  4.13519021  7.62697372\n",
      "  6.98870444  3.13184273 27.53291989  7.80220033]\n",
      "Epoch 83, Loss: [ 0.26002676  0.28428295 14.65964116  0.08403063  3.12924823  2.23049823\n",
      "  4.96688127  0.2544839  34.02348969  5.00325936 13.35018575  7.53464909\n",
      "  1.28543308  9.36099882  2.31332191  7.13639602  4.08510322  7.58000954\n",
      "  6.95501735  3.0938886  27.53415491  7.76338866]\n",
      "Epoch 84, Loss: [ 0.25451155  0.2795794  14.6008849   0.08260852  3.10486348  2.21675763\n",
      "  4.93363079  0.24848348 33.99453988  4.98496299 13.30459221  7.47443065\n",
      "  1.2713172   9.29718215  2.28441989  7.10691562  4.03621963  7.53400032\n",
      "  6.92191592  3.05686117 27.53522366  7.72536862]\n",
      "Epoch 85, Loss: [ 0.24917902  0.27500213 14.54291667  0.0812311   3.08093118  2.20329958\n",
      "  4.90096952  0.24269598 33.96601537  4.96700542 13.25960434  7.4153753\n",
      "  1.25750442  9.23461321  2.2561919   7.07798166  3.98849648  7.48891387\n",
      "  6.88938396  3.02072701 27.53612823  7.68811445]\n",
      "Epoch 86, Loss: [ 0.24402097  0.2705464  14.48571594  0.07989644  3.05743835  2.19011547\n",
      "  4.86887978  0.23711142 33.93790015  4.94937566 13.21520702  7.35744762\n",
      "  1.24398471  9.17325409  2.22861501  7.0495773   3.9418928   7.44471946\n",
      "  6.8574059   2.98545426 27.53687077  7.65160152]\n",
      "Epoch 87, Loss: [ 0.23902967  0.26620772 14.42926304  0.07860274  3.03437247  2.17719706\n",
      "  4.83734462  0.23172038 33.91017903  4.93206318 13.17138576  7.30061367\n",
      "  1.23074847  9.11306846  2.20166733  7.02168643  3.89636954  7.40138779\n",
      "  6.82596674  2.95101255 27.53745355  7.61580628]\n",
      "Epoch 88, Loss: [ 0.23419783  0.2619818  14.37353912  0.07734827  3.01172155  2.16453643\n",
      "  4.8063478   0.22651399 33.88283762  4.91505792 13.12812656  7.24484088\n",
      "  1.21778656  9.05402149  2.17532791  6.99429362  3.8518894   7.35889085\n",
      "  6.79505201  2.9173729  27.5378789   7.58070619]\n",
      "Epoch 89, Loss: [ 0.22951855  0.25786455 14.31852605  0.07613142  2.989474    2.15212598\n",
      "  4.77587374  0.22148389 33.85586226  4.89835028 13.08541597  7.190098\n",
      "  1.20509022  8.99607977  2.14957673  6.96738405  3.80841677  7.31720189\n",
      "  6.7646478   2.88450765 27.53814923  7.54627966]\n",
      "Epoch 90, Loss: [ 0.2249853   0.25385209 14.26420647  0.07495065  2.96761872  2.13995841\n",
      "  4.7459075   0.21662215 33.82924     4.88193105 13.04324102  7.13635502\n",
      "  1.19265107  8.93921125  2.12439461  6.94094351  3.76591765  7.27629534\n",
      "  6.73474064  2.8523904  27.538267    7.51250601]\n",
      "Epoch 91, Loss: [ 0.2205919   0.2499407  14.21056367  0.07380448  2.94614496  2.12802669\n",
      "  4.71643474  0.21192133 33.80295853  4.86579142 13.00158922  7.08358314\n",
      "  1.18046111  8.88338514  2.09976319  6.91495838  3.72435953  7.23614673\n",
      "  6.7053176   2.82099591 27.53823471  7.47936542]\n",
      "Epoch 92, Loss: [ 0.2163325   0.24612684 14.15758159  0.07269154  2.92504242  2.11632407\n",
      "  4.6874417   0.20737436 33.77700616  4.84992295 12.96044851  7.03175467\n",
      "  1.16851266  8.82857187  2.07566491  6.88941557  3.68371131  7.19673263\n",
      "  6.67636614  2.79030006 27.5380549   7.44683887]\n",
      "Epoch 93, Loss: [ 0.21220157  0.24240711 14.1052448   0.0716105   2.90430115  2.10484406\n",
      "  4.65891513  0.20297456 33.75137177  4.83431756 12.91980728  6.98084298\n",
      "  1.15679837  8.77474301  2.05208289  6.8643025   3.64394327  7.15803062\n",
      "  6.6478742   2.76027978 27.53773016  7.41490814]\n",
      "Epoch 94, Loss: [ 0.20819384  0.2387783  14.05353842  0.07056012  2.88391156  2.09358041\n",
      "  4.63084232  0.19871561 33.72604481  4.8189675  12.8796543   6.93082249\n",
      "  1.14531121  8.72187126  2.02900101  6.83960709  3.60502693  7.12001922\n",
      "  6.61983012  2.73091301 27.53726308  7.38355572]\n",
      "Epoch 95, Loss: [ 0.20430434  0.23523731 14.00244814  0.06953919  2.86386439  2.0825271\n",
      "  4.60321104  0.19459152 33.70101522  4.80386533 12.83997873  6.88166856\n",
      "  1.13404442  8.6699303   2.00640375  6.81531772  3.56693504  7.08267783\n",
      "  6.59222262  2.70217861 27.53665627  7.3527648 ]\n",
      "Epoch 96, Loss: [ 0.20052834  0.23178119 13.95196017  0.06854659  2.84415073  2.07167834\n",
      "  4.57600953  0.19059664 33.67627344  4.78900391 12.80077013  6.83335751\n",
      "  1.12299151  8.61889486  1.98427627  6.79142323  3.52964149  7.0459867\n",
      "  6.56504082  2.67405636 27.53591236  7.32251922]\n",
      "Epoch 97, Loss: [ 0.19686133  0.2284071  13.90206121  0.06758123  2.82476197  2.06102853\n",
      "  4.54922646  0.18672557 33.65181037  4.77437638 12.76201836  6.78586651\n",
      "  1.11214628  8.56874056  1.96260428  6.76791286  3.49312124  7.00992687\n",
      "  6.53827419  2.64652687 27.53503397  7.29280348]\n",
      "Epoch 98, Loss: [ 0.19329905  0.22511235 13.85273842  0.0666421   2.8056898   2.0505723\n",
      "  4.52285094  0.18297323 33.62761732  4.75997617 12.72371367  6.73917359\n",
      "  1.10150274  8.51944395  1.94137409  6.74477626  3.45735029  6.97448016\n",
      "  6.51191255  2.61957156 27.53402375  7.26360266]\n",
      "Epoch 99, Loss: [ 0.18983745  0.22189434 13.80397943  0.0657282   2.78692619  2.04030446\n",
      "  4.49687246  0.17933477 33.60368604  4.74579694 12.68584659  6.69325756\n",
      "  1.09105517  8.47098242  1.92057255  6.72200348  3.42230564  6.93962909\n",
      "  6.48594606  2.59317261 27.5328843   7.23490239]\n",
      "Epoch 100, Loss: [ 0.18647264  0.21875059 13.75577229  0.06483861  2.76846339  2.03022\n",
      "  4.47128091  0.1758056  33.58000864  4.73183261 12.64840799  6.64809803\n",
      "  1.08079804  8.42333419  1.90018699  6.69958492  3.3879652   6.90535689\n",
      "  6.46036519  2.56731294 27.53161827  7.20668887]\n",
      "Final Weights saved to weights.json\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T10:24:17.486758Z",
     "start_time": "2025-03-02T10:24:17.478510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def predict_crop(input_features):\n",
    "    input_features = scaler.transform([input_features])  # Normalize input\n",
    "    probs = neural_network(input_features[0], weights)  # Get probability distribution\n",
    "    probs = softmax(probs)  # Apply softmax to ensure probabilities sum to 1\n",
    "\n",
    "    crop_names = le.inverse_transform(np.arange(len(probs)))  # Get all crop names\n",
    "    predictions = [{\"crop\": crop, \"probability\": prob} for crop, prob in zip(crop_names, probs)]\n",
    "\n",
    "    return sorted(predictions, key=lambda x: x[\"probability\"], reverse=True)  # Sort by highest probability\n",
    "\n",
    "# Example prediction\n",
    "test_input = [150, 48, 17, 23, 73, 7, 66]  # Example soil & climate values\n",
    "predicted_crops = predict_crop(test_input)\n",
    "\n",
    "print(predicted_crops)"
   ],
   "id": "f7072eca79b17ff9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'crop': 'cotton', 'probability': 0.11206894162041381}, {'crop': 'maize', 'probability': 0.043177079164667384}, {'crop': 'watermelon', 'probability': 0.042286942811309604}, {'crop': 'coffee', 'probability': 0.04225488760861917}, {'crop': 'jute', 'probability': 0.042238523486823165}, {'crop': 'banana', 'probability': 0.04223766631498966}, {'crop': 'muskmelon', 'probability': 0.04223388302435986}, {'crop': 'blackgram', 'probability': 0.04223349979367939}, {'crop': 'rice', 'probability': 0.04223347212793774}, {'crop': 'chickpea', 'probability': 0.04223347081776787}, {'crop': 'orange', 'probability': 0.042233469951693636}, {'crop': 'kidneybeans', 'probability': 0.04223346958159296}, {'crop': 'mothbeans', 'probability': 0.04223346942617914}, {'crop': 'grapes', 'probability': 0.04223346940204834}, {'crop': 'lentil', 'probability': 0.042233469386743744}, {'crop': 'mungbean', 'probability': 0.042233469385530055}, {'crop': 'papaya', 'probability': 0.04223346936603279}, {'crop': 'apple', 'probability': 0.042233469346020014}, {'crop': 'mango', 'probability': 0.04223346934593319}, {'crop': 'pomegranate', 'probability': 0.042233469345896106}, {'crop': 'coconut', 'probability': 0.0422334693458838}, {'crop': 'pigeonpeas', 'probability': 0.042233469345878426}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/galich/miniconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 76
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
